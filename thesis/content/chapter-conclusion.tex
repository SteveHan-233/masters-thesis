\chapter{Conclusion}

In the introduction, we hypothesized that VR can be used as an intuitive interface to teach loco-manipulation skills to humanoids, and that the data collection can be massively scaled up by collecting demonstrations from video games. How are these hypotheses holding up against the data?

In the experiments, we found that VR is indeed a natural interface for teleoperating humanoid robots. We were able to easily collect hundreds of loco-manipulation demonstrations in simulation and on the real robot. We also confirmed that by using a whole-body controller to abstract away the low-level joint-torque controls, it is feasible for a baseline behavioral cloning algorithm to learn the high-level commands to perform simple tasks in simulation. However, the policy struggles to compensate for the tracking error produced by whole-body control when precise motion is required. Also, we have not yet successfully deployed the policy on the real robot. Nevertheless, this is the first attempt in literature to teach humanoids loco-manipulation tasks, and we believe that the next few iterations of our method can achieve greater success. 

The performance of our Python-based simulation is very far away from providing a smooth experience that video games demand. However, by switching to the C++ implementation of whole-body control, using a headset that directly connects to a computer's GPU, and optimizing our Mujoco simulation, we are confident that we can achieve a smooth simulation experience. Another option is to get rid of the whole-body control and simulated robot all-together and simply record the player's motions and observations. I believe that demonstrations collected this way can still be invaluable to humanoid loco-manipulation research in the future.
