\chapter{Introduction}

Robotics, Machine Learning (ML), and Virtual Reality (VR) are some of the most exciting and rapidly developing fields in technology today. It is perhaps no surprise that the marriage of these three technologies can have far-reaching impacts. Using VR, humans can control robots in an immersive simulation, or they can remotely teleoperate robots to perform dangerous tasks. The trajectories from the human demonstrations can then be used to train ML policies, which can enable robots to perform the tasks autonomously. 
However, due to the complexity of humanoid robots, the lack of large-scale data for training, and the difficulty of creating an interface for humans to control robots, there has been no research on teaching humanoid robots to perform locomotion and bi-manipulation tasks, as far as I'm aware. Also, although there is a large body of work on teleoperating robots using VR  and motion capture devices, I'm not aware of any attempt to use the teleoperation data to train a neural network policy to control the robot autonomously. Furthermore, these 
"telepresence" systems are usually very complicated and require expensive hardware, which makes them unsuitable for scaling up data collection in a distributed manner. 

In this thesis, I present a simple VR interface that uses the commonplace Oculus Quest 2 headset. I believe that compared to other humanoid teleoperation systems, the software architecture used in this project is uniquely positioned to be both adaptable to video games and accessible to the public. Although the interface is simple, it is nonetheless powerful enough to teach a humanoid robot to perform some simple tasks. In simulation, I hypothesize that this setup can be incorporated in VR video games to massively scale up data collection. VR games contain rich interactions with the virtual world, have built-in rewards to label successes and failures, and integrate with powerful physical simulation engines. As a result, they are perfect for collecting human demonstrations to potentially teach humanoids to perform the same tasks in the real world. For example, there are currently VR games that require players to cook in a kitchen, which is a valuable skill for humanoids to learn. In addition, on the real robot side, we could potentially distribute the data collection by letting users with VR headsets control the robot remotely. 
\section{Motivation}
\subsection{Large-scale Robot Learning Dataset}



\subsection{Humanoid Robots}
Humanoid robots have gained a lot of attention in recent years. After Boston Dynamic's Atlas made headlines by jumping and dancing with human-like dexterity, Tesla also entered the market by developing the cheap and mass-producible humanoid named Optimus. If the cost of the robot could be kept below \$20,000 like Elon Musk promised [cite], we would be entering a world where general purpose humanoids could replace humans for unsafe and repetitive tasks. Many startups are also getting a lot of funding recently to pursue humanoid robots. Apptronik is an Austin-based startup that aims to create humanoids that can work alongside people. One of their prototypes, DRACO 3, is the platform used for this thesis.

This interest in humanoids is justified by their versatility and social capabilities. They can be used as personal assistants, as companions for the elderly, as workers in factories, and as first responders in disaster zones. The morphology of humanoids enables them to easily adapt to the human-centered world that we live in. Every tool, every environment, and every task in our society is designed for the human form. It wouldn't make sense to redesign power tools or get rid of stairs for the convenience of robots, so creating robots that can take advantage of the existing infrastructure made for humans is extremely valuable. 

\section{Background}

Given the rapid development of humanoid hardware, cracking the code of human-like locomotion is the next big challenge. The most common approach is to use a combination of inverse kinematics and inverse dynamics to generate the joint torques that will move the robot to the desired pose. However, this approach is limited by the complexity of the inverse kinematics and inverse dynamics algorithms. Inverse kinematics is a non-convex optimization problem, and the inverse dynamics problem is also non-convex due to the non-linear constraints. This makes it difficult to find the optimal solution, and the solution is often suboptimal.
